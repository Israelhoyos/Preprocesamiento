{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"7_hr06ahXKd7"},"source":["# 7 - Carga y preprocesamiento de datos (Ejercicios)\n","\n","En este apartado, hemos estudiado uno de los componentes más importantes del ciclo de vida de los modelos de inteligencia artificial: la adquisición y manipulación de los datos. En los conjuntos de datos propuestos, tendremos por una parte la información relativa a los atributos de la muestra, y por otra los nombres de los mismos. Tu tarea será:\n","\n","* Importar desde consola por comandos Linux los ficheros oportunos.\n","* Leer los ficheros `data` y `names`.\n","* Explorar el fichero `names` para analizar qué tipo de expresiones regulares necesitas para identificar los nombres de las columnas en la metadata.\n","* Aplicar las transformaciones *regex* pertinentes y obtener los nombres de las columnas para construir los datos. *Pista: El nombre de la variable respuesta tendremos que añadirlo al final ya que no viene explícitamente citado*.\n","* Realizar un conveniente preprocesamiento de las variables en función de su tipo."]},{"cell_type":"markdown","metadata":{"id":"vd83apIaZtHH"},"source":["## 7.1 - *Adult* [dataset](https://archive.ics.uci.edu/ml/datasets/Adult)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ispLepCMZOoG"},"outputs":[],"source":["import os\n","import re\n","import requests\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CJ2qGh9XBwJ"},"outputs":[],"source":["# Comprobamos directorio actual\n","if not os.getcwd().split('\\\\')[-1]=='07-PREPROCESAMIENTO': os.chdir('..')\n","# Creamos una carpeta para que contenga a nuestro dataset\n","if not os.path.isdir('adult_dataset/'): os.mkdir('adult_dataset/')\n","# Movemos el directorio activo a esa localización\n","os.chdir('adult_dataset/')\n","# Descargamos el fichero que contiene los datos a nuestro directorio activo\n","URL='https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n","\n","# Descargamos la metadata asociada al conjunto de datos\n","URL='https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names'\n","\n","# Leemos datos\n","\n","\n","# Leemos metadata\n","\n","\n","# Regex\n","\n","\n","# Construimos el objeto pd.DataFrame\n","df = None"]},{"cell_type":"markdown","metadata":{"id":"THZ2TxfIcaBE"},"source":["## 7.2 - Beijing Multi-Site [Air Quality Data](https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data)\n","\n","En este conjunto de datos no tendremos que hacer un esfuerzo muy grande en lo relativo a estudiar la *metadata*, pero exploraremos una serie de comandos de Linux que nos será muy útil conocer:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bra5pAQQc1Pf"},"outputs":[],"source":["# Movemos el directorio activo a una nueva localización para este dataset\n","## Retrocedemos un nivel\n","if not os.getcwd().split('\\\\')[-1]=='07-PREPROCESAMIENTO': os.chdir('..')\n","## Creamos carpeta\n","if not os.path.isdir('air_quality_dataset/'): os.mkdir('air_quality_dataset/')\n","## Movemos directorio activo\n","os.chdir('air_quality_dataset/')\n","# Descargamos fichero comprimido\n","URL='https://archive.ics.uci.edu/ml/machine-learning-databases/00501/PRSA2017_Data_20130301-20170228.zip'\n","\n","# Descargamos el fichero que contiene los datos a nuestro directorio activo\n","\n","\n","# Nos movemos a la carpeta que contenía el zip\n","os.chdir('PRSA_Data_20130301-20170228')"]},{"cell_type":"markdown","metadata":{"id":"WavKUb55hd_2"},"source":["Ahora te toca, ¿eres capaz de leer todos los `csv`, concatenarlos y construir un `pd.DataFrame` en una sola línea de código?\n","\n","\n","```python\n","df = pd.concat([pd.read_csv(elem) for elem in os.listdir()]).reset_index(drop=True)\n","```"]},{"cell_type":"markdown","metadata":{"id":"DH3nPI72jN5z"},"source":["## 7.3 - Solar flare [dataset](https://archive.ics.uci.edu/ml/datasets/Solar+Flare)\n","\n","En este conjunto de datos, tendremos dos ficheros relativos a `data`, cuya primera fila serán las especificaciones temporales, por lo que deberemos quitarla, y además en los registros de datos las variables no vienen delimitadas por `','`, si no por espacios en blanco:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUEpFJ5mjRlG"},"outputs":[],"source":["# Movemos el directorio activo a una nueva localización para este dataset\n","## Retrocedemos dos niveles\n","if not os.getcwd().split('\\\\')[-1]=='07-PREPROCESAMIENTO': os.chdir('..')\n","if not os.getcwd().split('\\\\')[-1]=='07-PREPROCESAMIENTO': os.chdir('..')\n","## Creamos carpeta\n","if not os.path.isdir('solar_flare_dataset/'): os.mkdir('solar_flare_dataset/')\n","## Movemos directorio activo\n","os.chdir('air_quality_dataset/')\n","# Descargamos los ficheros que contienen los datos a nuestro directorio activo\n","URL_1='https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data1'\n","URL_2='https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data2'\n","\n","# Descargamos la metadata asociada al conjunto de datos\n","URL_names = 'https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.names'\n","\n","# Leemos datos\n","## Leemos primer fichero de datos\n","\n","## Leemos segundo fichero de datos\n","\n","## Combinamos ambas listas\n","\n","# Leemos metadata\n","\n","## Regex\n","\n","# Construimos el objeto pd.DataFrame\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"07 - Carga y preprocesamiento de datos (Ejercicios).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 ('venv_Data_Analytics': venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.7"},"vscode":{"interpreter":{"hash":"a1f6df9e7d128ead2e574a0735a2a900c09dba6447331164a691de269d7dfefe"}}},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"markdown","metadata":{"id":"7_hr06ahXKd7"},"source":["# 7 - Carga y preprocesamiento de datos (Ejercicios)\n","\n","En este apartado, hemos estudiado uno de los componentes más importantes del ciclo de vida de los modelos de inteligencia artificial: la adquisición y manipulación de los datos. En los conjuntos de datos propuestos, tendremos por una parte la información relativa a los atributos de la muestra, y por otra los nombres de los mismos. Tu tarea será:\n","\n","* Importar desde consola por comandos Linux los ficheros oportunos.\n","* Leer los ficheros `data` y `names`.\n","* Explorar el fichero `names` para analizar qué tipo de expresiones regulares necesitas para identificar los nombres de las columnas en la metadata.\n","* Aplicar las transformaciones *regex* pertinentes y obtener los nombres de las columnas para construir los datos. *Pista: El nombre de la variable respuesta tendremos que añadirlo al final ya que no viene explícitamente citado*.\n","* Realizar un conveniente preprocesmiento de las variables en función de su tipo."]},{"cell_type":"markdown","metadata":{"id":"vd83apIaZtHH"},"source":["## 7.1 - *Adult* [dataset](https://archive.ics.uci.edu/ml/datasets/Adult)\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ispLepCMZOoG"},"outputs":[],"source":["import os\n","import re\n","import requests\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-CJ2qGh9XBwJ"},"outputs":[],"source":["# Comprobamos directorio actual\n","if not os.getcwd().split('\\\\')[-1]=='07-PREPROCESAMIENTO':\n","    os.chdir('c:\\\\Users\\\\User\\\\Desktop\\\\Data_Analytics\\\\Bootcamp\\\\1_Módulo 1\\\\07-PREPROCESAMIENTO\\\\')\n","# Creamos una carpeta para que contenga a nuestro dataset\n","if not os.path.isdir('adult_dataset/'): os.mkdir('adult_dataset/')\n","# Movemos el directorio activo a esa localización\n","os.chdir('adult_dataset/')\n","# Descargamos el fichero que contiene los datos a nuestro directorio activo\n","response = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data')\n","with open(\"adult.data\", \"wb\") as f:\n","    f.write(response.content)\n","# Descargamos la metadata asociada al conjunto de datos\n","response = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names')\n","with open(\"adult.names\", \"wb\") as f:\n","    f.write(response.content)\n","# Leemos datos\n","with open('adult.data','r') as f:\n","    data = f.read().splitlines() # Dividimos el texto por saltos de línea\n","    data = [elem.split(',') for elem in data] # Dividimos cada línea por las comas y removemos líneas vacías\n","# Leemos metadata\n","with open(os.path.join(os.getcwd(),'adult.names'),'r') as f:\n","    metadata = f.read().splitlines()\n","# Regex\n","regex_fn = lambda text: re.findall('^[a-zA-Z-]+:{1}', text)\n","reg_text_fn = lambda text : re.findall('[a-zA-Z- ]+', text)\n","metadata_list = [regex_fn(elem)[0] for elem in metadata if regex_fn(elem)]\n","col_names = [reg_text_fn(elem)[0] for elem in metadata_list if reg_text_fn(elem)] + ['label']\n","# Construimos el objeto pd.DataFrame\n","df = pd.DataFrame(data=data, columns=col_names)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 32562 entries, 0 to 32561\n","Data columns (total 15 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   age             32562 non-null  object\n"," 1   workclass       32561 non-null  object\n"," 2   fnlwgt          32561 non-null  object\n"," 3   education       32561 non-null  object\n"," 4   education-num   32561 non-null  object\n"," 5   marital-status  32561 non-null  object\n"," 6   occupation      32561 non-null  object\n"," 7   relationship    32561 non-null  object\n"," 8   race            32561 non-null  object\n"," 9   sex             32561 non-null  object\n"," 10  capital-gain    32561 non-null  object\n"," 11  capital-loss    32561 non-null  object\n"," 12  hours-per-week  32561 non-null  object\n"," 13  native-country  32561 non-null  object\n"," 14  label           32561 non-null  object\n","dtypes: object(15)\n","memory usage: 3.7+ MB\n"]}],"source":["df.info()\n","# col_names"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df=df.head(32561)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Reemplazamos '?' por nulo\n","df = df.replace(' ?',np.NaN)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array(['39', '50', '38', '53', '28', '37', '49', '52', '31', '42', '30',\n","       '23', '32', '40', '34', '25', '43', '54', '35', '59', '56', '19',\n","       '20', '45', '22', '48', '21', '24', '57', '44', '41', '29', '18',\n","       '47', '46', '36', '79', '27', '67', '33', '76', '17', '55', '61',\n","       '70', '64', '71', '68', '66', '51', '58', '26', '60', '90', '75',\n","       '65', '77', '62', '63', '80', '72', '74', '69', '73', '81', '78',\n","       '88', '82', '83', '84', '85', '86', '87'], dtype=object)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df['age'].unique()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 32561 entries, 0 to 32560\n","Data columns (total 15 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   age             32561 non-null  object\n"," 1   workclass       30725 non-null  object\n"," 2   fnlwgt          32561 non-null  object\n"," 3   education       32561 non-null  object\n"," 4   education-num   32561 non-null  object\n"," 5   marital-status  32561 non-null  object\n"," 6   occupation      30718 non-null  object\n"," 7   relationship    32561 non-null  object\n"," 8   race            32561 non-null  object\n"," 9   sex             32561 non-null  object\n"," 10  capital-gain    32561 non-null  object\n"," 11  capital-loss    32561 non-null  object\n"," 12  hours-per-week  32561 non-null  object\n"," 13  native-country  31978 non-null  object\n"," 14  label           32561 non-null  object\n","dtypes: object(15)\n","memory usage: 3.7+ MB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 32561 entries, 0 to 32560\n","Data columns (total 15 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   age             32561 non-null  int64 \n"," 1   workclass       30725 non-null  object\n"," 2   fnlwgt          32561 non-null  int64 \n"," 3   education       32561 non-null  object\n"," 4   education-num   32561 non-null  int64 \n"," 5   marital-status  32561 non-null  object\n"," 6   occupation      30718 non-null  object\n"," 7   relationship    32561 non-null  object\n"," 8   race            32561 non-null  object\n"," 9   sex             32561 non-null  object\n"," 10  capital-gain    32561 non-null  int64 \n"," 11  capital-loss    32561 non-null  int64 \n"," 12  hours-per-week  32561 non-null  int64 \n"," 13  native-country  31978 non-null  object\n"," 14  label           32561 non-null  object\n","dtypes: int64(6), object(9)\n","memory usage: 3.7+ MB\n"]}],"source":["# Iteramos sobre las columnas del dataset\n","for col in df.columns:\n","    df[col] = pd.to_numeric(df[col], errors='ignore')\n","# Comprobamos que se han convertido con éxito\n","df.info()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Tomamos el mínimo y máximo de los datos\n","min_col, max_col = df['capital-gain'].min(), df['capital-gain'].max()\n","# Decidimos en cuántas cajas vamos a estratificar los datos\n","num_boxes = 5\n","# Creamos los valores que segmentarán las cajas\n","bins = np.linspace(min_col, max_col, num_boxes+1)\n","# Creamos la columna discretizada\n","df['capital-gain-disc'] = np.digitize(df['capital-gain'], bins)\n","\n","\n","# Tomamos el mínimo y máximo de los datos\n","min_col2, max_col2 = df['age'].min(), df['age'].max()\n","# Decidimos en cuántas cajas vamos a estratificar los datos\n","num_boxes2 = 2\n","# Creamos los valores que segmentarán las cajas\n","bins2 = np.linspace(min_col2, max_col2, num_boxes2+1)\n","# Creamos la columna discretizada\n","df['age-disc'] = np.digitize(df['age'], bins2)\n","\n","# Método auxiliar\n","def replace_missing_data(g):\n","    # Vemos qué columnas tienen valores nulos\n","    mis_cols = list(g.isnull().sum(axis=0)[g.isnull().sum(axis=0)>0].index)\n","    # Iteramos sobre ellas\n","    for col in mis_cols:\n","        # Si la variable es discreta,...\n","        if g[col].dtype in ['object']:\n","            mode_col = g[col].mode().values[0]\n","            g[col] = g[col].fillna(mode_col)\n","        # Si son números enteros\n","        elif g[col].dtype in ['int']:\n","            g[col] = g[col].fillna(g[col].median())\n","        # Si son números reales\n","        elif df[col].dtype in ['float']:\n","            g[col] = g[col].fillna(g[col].mean())\n","    # Devolvemos el DataFrame\n","    return g\n","\n","# Rellenamos valores por grupos\n","df = df.groupby(['capital-gain-disc', 'age-disc' , 'race', 'sex'],group_keys=False).apply(lambda g: replace_missing_data(g))\n","# Eliminamos columna añadida\n","df.drop('capital-gain-disc', axis=1, inplace=True)\n","df.drop('age-disc', axis=1, inplace=True)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32556</th>\n","      <td>27</td>\n","      <td>Private</td>\n","      <td>257302</td>\n","      <td>Assoc-acdm</td>\n","      <td>12</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Tech-support</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32557</th>\n","      <td>40</td>\n","      <td>Private</td>\n","      <td>154374</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;50K</td>\n","    </tr>\n","    <tr>\n","      <th>32558</th>\n","      <td>58</td>\n","      <td>Private</td>\n","      <td>151910</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Widowed</td>\n","      <td>Adm-clerical</td>\n","      <td>Unmarried</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32559</th>\n","      <td>22</td>\n","      <td>Private</td>\n","      <td>201490</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32560</th>\n","      <td>52</td>\n","      <td>Self-emp-inc</td>\n","      <td>287927</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>15024</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32561 rows × 15 columns</p>\n","</div>"],"text/plain":["       age          workclass  fnlwgt    education  education-num  \\\n","0       39          State-gov   77516    Bachelors             13   \n","1       50   Self-emp-not-inc   83311    Bachelors             13   \n","2       38            Private  215646      HS-grad              9   \n","3       53            Private  234721         11th              7   \n","4       28            Private  338409    Bachelors             13   \n","...    ...                ...     ...          ...            ...   \n","32556   27            Private  257302   Assoc-acdm             12   \n","32557   40            Private  154374      HS-grad              9   \n","32558   58            Private  151910      HS-grad              9   \n","32559   22            Private  201490      HS-grad              9   \n","32560   52       Self-emp-inc  287927      HS-grad              9   \n","\n","            marital-status          occupation    relationship    race  \\\n","0            Never-married        Adm-clerical   Not-in-family   White   \n","1       Married-civ-spouse     Exec-managerial         Husband   White   \n","2                 Divorced   Handlers-cleaners   Not-in-family   White   \n","3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n","4       Married-civ-spouse      Prof-specialty            Wife   Black   \n","...                    ...                 ...             ...     ...   \n","32556   Married-civ-spouse        Tech-support            Wife   White   \n","32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n","32558              Widowed        Adm-clerical       Unmarried   White   \n","32559        Never-married        Adm-clerical       Own-child   White   \n","32560   Married-civ-spouse     Exec-managerial            Wife   White   \n","\n","           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n","0         Male          2174             0              40   United-States   \n","1         Male             0             0              13   United-States   \n","2         Male             0             0              40   United-States   \n","3         Male             0             0              40   United-States   \n","4       Female             0             0              40            Cuba   \n","...        ...           ...           ...             ...             ...   \n","32556   Female             0             0              38   United-States   \n","32557     Male             0             0              40   United-States   \n","32558   Female             0             0              40   United-States   \n","32559     Male             0             0              20   United-States   \n","32560   Female         15024             0              40   United-States   \n","\n","        label  \n","0       <=50K  \n","1       <=50K  \n","2       <=50K  \n","3       <=50K  \n","4       <=50K  \n","...       ...  \n","32556   <=50K  \n","32557    >50K  \n","32558   <=50K  \n","32559   <=50K  \n","32560    >50K  \n","\n","[32561 rows x 15 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["df['label']=np.where(df['label']==' >50K', True, False)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["array([' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th',\n","       ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th',\n","       ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th',\n","       ' Preschool', ' 12th'], dtype=object)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df['education'].unique()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 32561 entries, 0 to 32560\n","Data columns (total 15 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   age             32561 non-null  int64 \n"," 1   workclass       32561 non-null  object\n"," 2   fnlwgt          32561 non-null  int64 \n"," 3   education       32561 non-null  object\n"," 4   education-num   32561 non-null  int64 \n"," 5   marital-status  32561 non-null  object\n"," 6   occupation      32561 non-null  object\n"," 7   relationship    32561 non-null  object\n"," 8   race            32561 non-null  object\n"," 9   sex             32561 non-null  object\n"," 10  capital-gain    32561 non-null  int64 \n"," 11  capital-loss    32561 non-null  int64 \n"," 12  hours-per-week  32561 non-null  int64 \n"," 13  native-country  32561 non-null  object\n"," 14  label           32561 non-null  bool  \n","dtypes: bool(1), int64(6), object(8)\n","memory usage: 4.8+ MB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"THZ2TxfIcaBE"},"source":["## 7.2 - Beijing Multi-Site [Air Quality Data](https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data)\n","\n","En este conjunto de datos no tendremos que hacer un esfuerzo muy grande en lo relativo a estudiar la *metadata*, pero exploraremos una serie de comandos de Linux que nos será muy útil conocer:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"bra5pAQQc1Pf"},"outputs":[],"source":["# Movemos el directorio activo a una nueva localización para este dataset\n","## Retrocedemos un nivel\n","if not os.getcwd().split('\\\\')[-1]=='07-PREPROCESAMIENTO': os.chdir('c:\\\\Users\\\\User\\\\Desktop\\\\Data_Analytics\\\\Bootcamp\\\\1_Módulo 1\\\\07-PREPROCESAMIENTO')\n","## Creamos carpeta\n","if not os.path.isdir('content/'): os.mkdir('content/')\n","os.chdir('content')\n","if not os.path.isdir('air_quality_dataset/'): os.mkdir('air_quality_dataset/')\n","## Movemos directorio activo\n","os.chdir('air_quality_dataset')\n","# Descargamos fichero comprimido\n","response = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/00501/PRSA2017_Data_20130301-20170228.zip')\n","with open(\"PRSA2017_Data_20130301-20170228.zip\", \"wb\") as f:\n","    f.write(response.content)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import zipfile\n","zipfile.ZipFile('PRSA2017_Data_20130301-20170228.zip','r').extractall()\n","os.chdir('PRSA_Data_20130301-20170228')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\User\\\\Desktop\\\\Data_Analytics\\\\Bootcamp\\\\1_Módulo 1\\\\07-PREPROCESAMIENTO\\\\content\\\\air_quality_dataset\\\\PRSA_Data_20130301-20170228'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["os.getcwd()\n","# os.listdir('PRSA_Data_20130301-20170228')\n","# os.listdir(os.getcwd())"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["df = pd.concat([pd.read_csv(elem) for elem in os.listdir(os.getcwd())]).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"WavKUb55hd_2"},"source":["Ahora te toca, ¿eres capaz de leer todos los `csv`, concatenarlos y construir un `pd.DataFrame` en una sola línea de código?\n","\n","\n","```python\n","df = pd.concat([pd.read_csv(elem) for elem in os.listdir()]).reset_index(drop=True)\n","```"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["           No  year  month  day  hour  PM2.5  PM10   SO2   NO2     CO    O3  \\\n","0           1  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  77.0   \n","1           2  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  77.0   \n","2           3  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  73.0   \n","3           4  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  72.0   \n","4           5  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  72.0   \n","...       ...   ...    ...  ...   ...    ...   ...   ...   ...    ...   ...   \n","420763  35060  2017      2   28    19   11.0  32.0   3.0  24.0  400.0  72.0   \n","420764  35061  2017      2   28    20   13.0  32.0   3.0  41.0  500.0  50.0   \n","420765  35062  2017      2   28    21   14.0  28.0   4.0  38.0  500.0  54.0   \n","420766  35063  2017      2   28    22   12.0  23.0   4.0  30.0  400.0  59.0   \n","420767  35064  2017      2   28    23   13.0  19.0   4.0  38.0  600.0  49.0   \n","\n","        TEMP    PRES  DEWP  RAIN   wd  WSPM        station  \n","0       -0.7  1023.0 -18.8   0.0  NNW   4.4   Aotizhongxin  \n","1       -1.1  1023.2 -18.2   0.0    N   4.7   Aotizhongxin  \n","2       -1.1  1023.5 -18.2   0.0  NNW   5.6   Aotizhongxin  \n","3       -1.4  1024.5 -19.4   0.0   NW   3.1   Aotizhongxin  \n","4       -2.0  1025.2 -19.5   0.0    N   2.0   Aotizhongxin  \n","...      ...     ...   ...   ...  ...   ...            ...  \n","420763  12.5  1013.5 -16.2   0.0   NW   2.4  Wanshouxigong  \n","420764  11.6  1013.6 -15.1   0.0  WNW   0.9  Wanshouxigong  \n","420765  10.8  1014.2 -13.3   0.0   NW   1.1  Wanshouxigong  \n","420766  10.5  1014.4 -12.9   0.0  NNW   1.2  Wanshouxigong  \n","420767   8.6  1014.1 -15.9   0.0  NNE   1.3  Wanshouxigong  \n","\n","[420768 rows x 18 columns]\n"]}],"source":["print(df)"]},{"cell_type":"markdown","metadata":{"id":"DH3nPI72jN5z"},"source":["## 7.3 - Solar flare [dataset](https://archive.ics.uci.edu/ml/datasets/Solar+Flare)\n","\n","En este conjunto de datos, tendremos dos ficheros relativos a `data`, cuya primera fila serán las especificaciones temporales, por lo que deberemos quitarla, y además en los registros de datos las variables no vienen delimitadas por `','`, si no por espacios en blanco:"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# Movemos el directorio activo a una nueva localización para este dataset\n","## Retrocedemos dos niveles\n","os.chdir('c:\\\\Users\\\\User\\\\Desktop\\\\Data_Analytics\\\\Bootcamp\\\\1_Módulo 1\\\\07-PREPROCESAMIENTO\\\\content\\\\')\n","\n","## Creamos carpeta\n","if not os.path.isdir('solar_flare_dataset/'): os.mkdir('solar_flare_dataset')\n","\n","## Movemos directorio activo\n","os.chdir('solar_flare_dataset')\n","\n","# Descargamos los ficheros que contienen los datos a nuestro directorio activo\n","response = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data1')\n","with open(\"flare.data1\", \"wb\") as f:\n","    f.write(response.content) \n","\n","response = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data2')\n","with open(\"flare.data2\", \"wb\") as f:\n","    f.write(response.content) \n","\n","# Descargamos la metadata asociada al conjunto de datos\n","response = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.names')\n","with open(\"flare.names\", \"wb\") as f:\n","    f.write(response.content) \n","\n","# Leemos datos\n","## Leemos primer fichero de datos\n","with open(os.path.join(os.getcwd(),'flare.data1'),'r') as f:\n","    data1 = f.read().splitlines() # Dividimos el texto por saltos de línea\n","    data1 = [elem.split(' ') for elem in data1 if elem!=''] # Dividimos cada línea por las comas y removemos líneas vacías\n","    data1 = data1[1:] # Quitamos la línea de metadata temporal\n","## Leemos segundo fichero de datos\n","with open(os.path.join(os.getcwd(),'flare.data2'),'r') as f:\n","    data2 = f.read().splitlines() # Dividimos el texto por saltos de línea\n","    data2 = [elem.split(' ') for elem in data2 if elem!=''] # Dividimos cada línea por las comas y removemos líneas vacías\n","    data2 = data2[1:] # Quitamos la línea de metadata temporal\n","## Combinamos ambas listas\n","data = data1+data2\n","# Leemos metadata\n","with open(os.path.join(os.getcwd(),'flare.names'),'r') as f:\n","    metadata = f.read().splitlines()\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["['1. TItle: Solar Flare database',\n"," '',\n"," '2. Source Information',\n"," '   -- Donor: Gary Bradshaw <gbradshaw@clipr.colorado.EDU>',\n"," '   -- Date: 3/89',\n"," '',\n"," '3. Past Usage:',\n"," '   -- Gary Bradshaw: (Class Attributes were collapsed to 0 and >0)',\n"," '   -- See the past-usage file for a note written by Gary Bradshaw',\n"," '',\n"," '4. Relevant Information:',\n"," '   -- The database contains 3 potential classes, one for the number of times a',\n"," '      certain type of solar flare occured in a 24 hour period.',\n"," '   -- Each instance represents captured features for 1 active region on the ',\n"," '      sun.',\n"," '   -- The data are divided into two sections. The second section (flare.data2)',\n"," '      has had much more error correction applied to the it, and has ',\n"," '      consequently been treated as more reliable.',\n"," '',\n"," '5. Number of Instances:  flare.data1: 323, flare.data2: 1066',\n"," '',\n"," '6. Number of attributes:  13 (includes 3 class attributes)',\n"," '',\n"," '7. Attribute Information:',\n"," '   1. Code for class (modified Zurich class)  (A,B,C,D,E,F,H)',\n"," '   2. Code for largest spot size              (X,R,S,A,H,K)',\n"," '   3. Code for spot distribution              (X,O,I,C)',\n"," '   4. Activity                                (1 = reduced, 2 = unchanged)',\n"," '   5. Evolution                               (1 = decay, 2 = no growth, ',\n"," '                                               3 = growth)',\n"," '   6. Previous 24 hour flare activity code    (1 = nothing as big as an M1,',\n"," '                                               2 = one M1,',\n"," '                                               3 = more activity than one M1)',\n"," '   7. Historically-complex                    (1 = Yes, 2 = No)',\n"," '   8. Did region become historically complex  (1 = yes, 2 = no) ',\n"," \"      on this pass across the sun's disk\",\n"," '   9. Area                                    (1 = small, 2 = large)',\n"," '  10. Area of the largest spot                (1 = <=5, 2 = >5)',\n"," '',\n"," ' From all these predictors three classes of flares are predicted, which are ',\n"," ' represented in the last three columns.',\n"," '',\n"," '  11. C-class flares production by this region    Number  ',\n"," '      in the following 24 hours (common flares)',\n"," '  12. M-class flares production by this region    Number',\n"," '      in the following 24 hours (moderate flares)',\n"," '  13. X-class flares production by this region    Number',\n"," '      in the following 24 hours (severe flares)',\n"," '',\n"," '8. Missing values: None',\n"," '',\n"," '9. Class Distribution:',\n"," '',\n"," '   flare.data1:   ',\n"," '                    0   1  2  4 Total',\n"," '   C-class flares 287  29  7  0 323',\n"," '   M-class flares 291  24  6  2 323',\n"," '   X-class flares 316   7  0  0 323',\n"," '',\n"," '   flare.data2:',\n"," '',\n"," '                    0    1  2  3  4  5  6  7  8  Total',\n"," '   C-class flares  884 112 33 20  9  4  3  0  1  1066',\n"," '   M-class flares 1030  29  3  2  1  0  1  0  0  1066',\n"," '   X-class flares 1061   4  1  0  0  0  0  0  0  1066']"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["metadata"]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[],"source":["regex_fn1 = lambda text: re.findall('^\\s+[0-9]+\\.{1}\\s{1}[a-zA-Z- 0-9]+|\\({1}', text)\n","reg_text_fn1 = lambda text : re.findall('[a-zA-Z-]{1}[a-zA-Z-0-9\\s]+', text)\n","metadata_list1 = [regex_fn1(elem)[0].strip() for elem in metadata if regex_fn1(elem)]\n","col_names1 = [reg_text_fn1(elem)[0] for elem in metadata_list1 if reg_text_fn1(elem)]"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[],"source":["col_names=[elem.replace('    Number','') for elem in col_names1]"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[{"data":{"text/plain":["['Code for class',\n"," 'Code for largest spot size',\n"," 'Code for spot distribution',\n"," 'Activity',\n"," 'Evolution',\n"," 'Previous 24 hour flare activity code',\n"," 'Historically-complex',\n"," 'Did region become historically complex',\n"," 'Area',\n"," 'Area of the largest spot',\n"," 'C-class flares production by this region',\n"," 'M-class flares production by this region',\n"," 'X-class flares production by this region']"]},"execution_count":144,"metadata":{},"output_type":"execute_result"}],"source":["col_names"]},{"cell_type":"code","execution_count":145,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Code for class</th>\n","      <th>Code for largest spot size</th>\n","      <th>Code for spot distribution</th>\n","      <th>Activity</th>\n","      <th>Evolution</th>\n","      <th>Previous 24 hour flare activity code</th>\n","      <th>Historically-complex</th>\n","      <th>Did region become historically complex</th>\n","      <th>Area</th>\n","      <th>Area of the largest spot</th>\n","      <th>C-class flares production by this region</th>\n","      <th>M-class flares production by this region</th>\n","      <th>X-class flares production by this region</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C</td>\n","      <td>S</td>\n","      <td>O</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D</td>\n","      <td>S</td>\n","      <td>O</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>S</td>\n","      <td>O</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>D</td>\n","      <td>S</td>\n","      <td>O</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>O</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1384</th>\n","      <td>H</td>\n","      <td>S</td>\n","      <td>X</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1385</th>\n","      <td>H</td>\n","      <td>S</td>\n","      <td>X</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1386</th>\n","      <td>C</td>\n","      <td>S</td>\n","      <td>O</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1387</th>\n","      <td>H</td>\n","      <td>R</td>\n","      <td>X</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1388</th>\n","      <td>B</td>\n","      <td>X</td>\n","      <td>O</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1389 rows × 13 columns</p>\n","</div>"],"text/plain":["     Code for class Code for largest spot size Code for spot distribution  \\\n","0                 C                          S                          O   \n","1                 D                          S                          O   \n","2                 C                          S                          O   \n","3                 D                          S                          O   \n","4                 D                          A                          O   \n","...             ...                        ...                        ...   \n","1384              H                          S                          X   \n","1385              H                          S                          X   \n","1386              C                          S                          O   \n","1387              H                          R                          X   \n","1388              B                          X                          O   \n","\n","     Activity Evolution Previous 24 hour flare activity code  \\\n","0           1         2                                    1   \n","1           1         3                                    1   \n","2           1         3                                    1   \n","3           1         3                                    1   \n","4           1         3                                    1   \n","...       ...       ...                                  ...   \n","1384        1         2                                    1   \n","1385        2         2                                    1   \n","1386        1         2                                    1   \n","1387        1         2                                    1   \n","1388        1         1                                    1   \n","\n","     Historically-complex Did region become historically complex Area  \\\n","0                       1                                      2    1   \n","1                       1                                      2    1   \n","2                       1                                      2    1   \n","3                       1                                      2    1   \n","4                       1                                      2    1   \n","...                   ...                                    ...  ...   \n","1384                    1                                      1    1   \n","1385                    1                                      2    1   \n","1386                    2                                      2    1   \n","1387                    1                                      2    1   \n","1388                    1                                      2    1   \n","\n","     Area of the largest spot C-class flares production by this region  \\\n","0                           2                                        0   \n","1                           2                                        0   \n","2                           1                                        0   \n","3                           2                                        0   \n","4                           2                                        0   \n","...                       ...                                      ...   \n","1384                        1                                        0   \n","1385                        1                                        0   \n","1386                        1                                        0   \n","1387                        1                                        0   \n","1388                        1                                        0   \n","\n","     M-class flares production by this region  \\\n","0                                           0   \n","1                                           0   \n","2                                           0   \n","3                                           0   \n","4                                           0   \n","...                                       ...   \n","1384                                        0   \n","1385                                        0   \n","1386                                        0   \n","1387                                        0   \n","1388                                        0   \n","\n","     X-class flares production by this region  \n","0                                           0  \n","1                                           0  \n","2                                           0  \n","3                                           0  \n","4                                           0  \n","...                                       ...  \n","1384                                        0  \n","1385                                        0  \n","1386                                        0  \n","1387                                        0  \n","1388                                        0  \n","\n","[1389 rows x 13 columns]"]},"execution_count":145,"metadata":{},"output_type":"execute_result"}],"source":["# Construimos el objeto pd.DataFrame\n","df = pd.DataFrame(data=data, columns=col_names)\n","df"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"07 - Carga y preprocesamiento de datos (Ejercicios).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 ('venv_Data_Analytics': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"vscode":{"interpreter":{"hash":"a1f6df9e7d128ead2e574a0735a2a900c09dba6447331164a691de269d7dfefe"}}},"nbformat":4,"nbformat_minor":0}
